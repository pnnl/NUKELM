{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "This material was prepared as an account of work sponsored by an agency of the United States Government.  Neither the United States Government nor the United States Department of Energy, nor Battelle, nor any of their employees, nor any jurisdiction or organization that has cooperated in the development of these materials, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness or any information, apparatus, product, software, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof, or Battelle Memorial Institute. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof.\n",
    "\n",
    "PACIFIC NORTHWEST NATIONAL LABORATORY operated by BATTELLE for the UNITED STATES DEPARTMENT OF ENERGY under Contract DE-AC05-76RL01830."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "from nukelm.analyze.BERTopic import BERTopic\n",
    "from nukelm.analyze.umap_comparisons import PLOT_KWARGS, UMAP_KWARGS, plot_points\n",
    "\n",
    "\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "output_dir = PROJECT_DIR / \"data\" / \"08_reporting\" / \"bertopic\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "AGG_METHOD = \"CLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_trained = datasets.load_from_disk(str(PROJECT_DIR / \"data\" / \"07_model_output\" / \"roberta-large-trained-1\"))\n",
    "dataset_ots = datasets.load_from_disk(str(PROJECT_DIR / \"data\" / \"07_model_output\" / \"roberta-large-ots-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_trained = umap.UMAP(**UMAP_KWARGS).fit(dataset_trained[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_ots = umap.UMAP(**UMAP_KWARGS).fit(dataset_ots[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_trained = mapper_trained.transform(dataset_trained[AGG_METHOD])\n",
    "points_ots = mapper_ots.transform(dataset_ots[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic applied to model with continued pre-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTOPIC_KWARGS = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 100,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"umap_metric\": \"euclidean\",\n",
    "    \"random_state\": 42,\n",
    "    \"min_cluster_size\": 25,\n",
    "    \"min_samples\": None,\n",
    "    \"cluster_selection_epsilon\": 0.0,\n",
    "    \"hdbscan_metric\": \"euclidean\",\n",
    "    \"alpha\": 1.0,\n",
    "    \"cluster_selection_method\": \"eom\",\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = BERTopic(**BERTOPIC_KWARGS)\n",
    "labels_trained, _ = model_trained.fit_transform(dataset_trained[\"text\"], np.array(dataset_trained[AGG_METHOD]))\n",
    "labels_ots = labels_trained  # plot with labels from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set_trained = set(labels_trained + labels_ots)\n",
    "label_map_trained = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set_trained) + 1)}\n",
    "label_map_trained[-1] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{f\"Cluster {i+1: 2d}\" if i + 1 > 0 else \"None\": model_trained.get_topic(i) for i in labels_set_trained}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_trained = plot_points(\n",
    "    (points_trained, points_ots),\n",
    "    (labels_trained, labels_ots),\n",
    "    (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\"),\n",
    "    label_map_trained,\n",
    "    True,\n",
    "    **PLOT_KWARGS,\n",
    ")\n",
    "fig_trained.savefig(output_dir / \"trained-clusters.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic applied to model without continued pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTOPIC_KWARGS = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 100,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"umap_metric\": \"euclidean\",\n",
    "    \"random_state\": 42,\n",
    "    \"min_cluster_size\": 25,\n",
    "    \"min_samples\": None,\n",
    "    \"cluster_selection_epsilon\": 0.0,\n",
    "    \"hdbscan_metric\": \"euclidean\",\n",
    "    \"alpha\": 1.0,\n",
    "    \"cluster_selection_method\": \"eom\",\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ots = BERTopic(**BERTOPIC_KWARGS)\n",
    "labels_ots, _ = model_ots.fit_transform(dataset_ots[\"text\"], np.array(dataset_ots[AGG_METHOD]))\n",
    "labels_trained = labels_ots  # plot with labels from off-the-shelf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set_ots = set(labels_trained + labels_ots)\n",
    "label_map_ots = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set_ots) + 1)}\n",
    "label_map_ots[-1] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{f\"Cluster {i+1: 2d}\" if i + 1 > 0 else \"None\": model_ots.get_topic(i) for i in labels_set_ots}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ots = plot_points(\n",
    "    (points_trained, points_ots),\n",
    "    (labels_trained, labels_ots),\n",
    "    (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\"),\n",
    "    label_map_ots,\n",
    "    True,\n",
    "    **PLOT_KWARGS,\n",
    ")\n",
    "fig_ots.savefig(output_dir / \"ots-clusters.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_points(\n",
    "#     (points_trained, points_ots),\n",
    "#     (_labels_trained, _labels_ots),\n",
    "#     None,\n",
    "# #     (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     label_map,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.axes[0].set_xlim(-2.5, 17.5)\n",
    "# fig.axes[1].set_xlim(-2.5, 17.5)\n",
    "# fig.axes[0].set_ylim(-2.5, 17.5)\n",
    "# fig.axes[1].set_ylim(-2.5, 17.5)\n",
    "# fig.axes[0].set_xticks([0, 5, 10, 15])\n",
    "# fig.axes[0].set_yticks([0, 5, 10, 15])\n",
    "# fig.axes[1].set_xticks([0, 5, 10, 15])\n",
    "# fig.axes[1].set_yticks([0, 5, 10, 15])\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.axes[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(\"clusters.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_points(\n",
    "#     (points_trained, points_ots),\n",
    "#     (_labels_trained, _labels_ots),\n",
    "#     None,\n",
    "# #     (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     label_map,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_points(\n",
    "#     (points_trained, points_ots),\n",
    "#     (dataset_trained[\"label\"], dataset_ots[\"label\"]),\n",
    "#     (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     None,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.axes[0].set_xlim(-2.5, 17.5)\n",
    "# fig.axes[1].set_xlim(-2.5, 17.5)\n",
    "# fig.axes[0].set_ylim(-2.5, 17.5)\n",
    "# fig.axes[1].set_ylim(-2.5, 17.5)\n",
    "# fig.axes[0].set_xticks([0, 5, 10, 15])\n",
    "# fig.axes[0].set_yticks([0, 5, 10, 15])\n",
    "# fig.axes[1].set_xticks([0, 5, 10, 15])\n",
    "# fig.axes[1].set_yticks([0, 5, 10, 15])\n",
    "\n",
    "# fig.axes[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(\"umap.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final plot for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    \"nuke\": \"NFC-Related\",\n",
    "    \"not-nuke\": \"Other\",\n",
    "}\n",
    "PLOT_KWARGS = {\n",
    "    \"linestyle\": \"None\",\n",
    "    \"marker\": \".\",\n",
    "    \"alpha\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels_trained = [label if label >= 0 else int(1e5) for label in labels_trained]\n",
    "_labels_ots = [label if label >= 0 else int(1e5) for label in labels_ots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set = set(_labels_trained + _labels_ots)\n",
    "label_map = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set) + 1)}\n",
    "\n",
    "label_map[int(1e5)] = \"Outlier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = (points_trained, points_ots)[::-1]\n",
    "labels = ((dataset_trained[\"label\"], dataset_ots[\"label\"])[::-1], (_labels_trained, _labels_ots)[::-1])\n",
    "label_maps = (LABEL_MAP, label_map)\n",
    "titles = (r\"\\textsc{NukeLM}\", r\"\\textsc{RoBERTa} Large\")[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        _points = points[j]\n",
    "        ax = axes[i, j]\n",
    "        _labels = labels[i][j]\n",
    "        unique_labels = sorted(list(set(_labels)))\n",
    "        idx = {}\n",
    "        for class_name in unique_labels:\n",
    "            idx[class_name] = [i for i, label in enumerate(_labels) if label == class_name]\n",
    "        for class_name in unique_labels:\n",
    "            ax.plot(\n",
    "                _points[idx[class_name], 0],\n",
    "                _points[idx[class_name], 1],\n",
    "                label=label_maps[i][class_name],\n",
    "                **PLOT_KWARGS,\n",
    "            )\n",
    "        if i == 0:\n",
    "            ax.set_title(titles[j])\n",
    "        ax.legend(loc=\"upper right\")  # loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        if j == 0:\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"NFC Labels\")\n",
    "            if i == 1:\n",
    "                ax.set_ylabel(\"BERTopic Cluster Labels\")\n",
    "        ax.set_xlim(-2.5, 25)\n",
    "        ax.set_ylim(-2.5, 18)\n",
    "        ax.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "        ax.set_yticks([0, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_dir / \"combined-plots.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
