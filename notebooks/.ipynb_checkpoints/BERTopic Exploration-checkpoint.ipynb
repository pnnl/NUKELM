{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7ec2b52a3bff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnukelm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBERTopic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnukelm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mumap_comparisons\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPLOT_KWARGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUMAP_KWARGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pazd068\\onedrive - pnnl\\documents\\bitbucket\\dude\\nukelm\\src\\nukelm\\analyze\\BERTopic.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nukelm\\lib\\site-packages\\hdbscan\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhdbscan_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHDBSCAN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrobust_single_linkage_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRobustSingleLinkage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrobust_single_linkage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidity\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidity_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m from .prediction import (approximate_predict,\n\u001b[0;32m      5\u001b[0m                          \u001b[0mmembership_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nukelm\\lib\\site-packages\\hdbscan\\hdbscan_.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m from ._hdbscan_linkage import (single_linkage,\n\u001b[0m\u001b[0;32m     22\u001b[0m                                \u001b[0mmst_linkage_core\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                \u001b[0mmst_linkage_core_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mhdbscan/_hdbscan_linkage.pyx\u001b[0m in \u001b[0;36minit hdbscan._hdbscan_linkage\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "from nukelm.analyze.BERTopic import BERTopic\n",
    "from nukelm.analyze.umap_comparisons import PLOT_KWARGS, UMAP_KWARGS, plot_points\n",
    "\n",
    "\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "output_dir = PROJECT_DIR / \"data\" / \"08_reporting\" / \"bertopic\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "AGG_METHOD = \"CLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_trained_1 = datasets.load_from_disk(str(PROJECT_DIR / \"data\" / \"07_model_output\" / \"roberta-large-trained-1\"))\n",
    "dataset_ots_1 = datasets.load_from_disk(str(PROJECT_DIR / \"data\" / \"07_model_output\" / \"roberta-large-ots-1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_trained_1 = umap.UMAP(**UMAP_KWARGS).fit(dataset_trained_1[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_ots_1 = umap.UMAP(**UMAP_KWARGS).fit(dataset_ots_1[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points_trained_1 = mapper_trained_1.transform(dataset_trained_1[AGG_METHOD])\n",
    "points_ots_1 = mapper_ots_1.transform(dataset_ots_1[AGG_METHOD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic applied to model with continued pre-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTOPIC_KWARGS = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 100,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"umap_metric\": \"euclidean\",\n",
    "    \"random_state\": 42,\n",
    "    \"min_cluster_size\": 25,\n",
    "    \"min_samples\": None,\n",
    "    \"cluster_selection_epsilon\": 0.0,\n",
    "    \"hdbscan_metric\": \"euclidean\",\n",
    "    \"alpha\": 1.0,\n",
    "    \"cluster_selection_method\": \"eom\",\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained_1 = BERTopic(**BERTOPIC_KWARGS)\n",
    "labels_trained_1, _ = model_trained_1.fit_transform(dataset_trained_1[\"text\"], np.array(dataset_trained_1[AGG_METHOD]))\n",
    "labels_ots_1 = labels_trained_1  # plot with labels from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set_trained_1 = set(labels_trained_1 + labels_ots_1)\n",
    "label_map_trained_1 = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set_trained_1) + 1)}\n",
    "label_map_trained_1[-1] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{f\"Cluster {i+1: 2d}\" if i + 1 > 0 else \"None\": model_trained_1.get_topic(i) for i in labels_set_trained_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_trained_1 = plot_points(\n",
    "    (points_trained_1, points_ots_1),\n",
    "    (labels_trained_1, labels_ots_1),\n",
    "    (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\"),\n",
    "    label_map_trained_1,\n",
    "    True,\n",
    "    **PLOT_KWARGS,\n",
    ")\n",
    "fig_trained_1.savefig(output_dir / \"trained-clusters.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic applied to model without continued pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTOPIC_KWARGS = {\n",
    "    \"n_neighbors\": 15,\n",
    "    \"n_components\": 100,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"umap_metric\": \"euclidean\",\n",
    "    \"random_state\": 42,\n",
    "    \"min_cluster_size\": 25,\n",
    "    \"min_samples\": None,\n",
    "    \"cluster_selection_epsilon\": 0.0,\n",
    "    \"hdbscan_metric\": \"euclidean\",\n",
    "    \"alpha\": 1.0,\n",
    "    \"cluster_selection_method\": \"eom\",\n",
    "    \"verbose\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ots_1 = BERTopic(**BERTOPIC_KWARGS)\n",
    "labels_ots_1, _ = model_ots_1.fit_transform(dataset_ots_1[\"text\"], np.array(dataset_ots_1[AGG_METHOD]))\n",
    "labels_trained_1 = labels_ots_1  # plot with labels from off-the-shelf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set_ots_1 = set(labels_trained_1 + labels_ots_1)\n",
    "label_map_ots_1 = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set_ots_1) + 1)}\n",
    "label_map_ots_1[-1] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{f\"Cluster {i+1: 2d}\" if i + 1 > 0 else \"None\": model_ots_1.get_topic(i) for i in labels_set_ots_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ots_1 = plot_points(\n",
    "    (points_trained_1, points_ots_1),\n",
    "    (labels_trained_1, labels_ots_1),\n",
    "    (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\"),\n",
    "    label_map_ots_1,\n",
    "    True,\n",
    "    **PLOT_KWARGS,\n",
    ")\n",
    "fig_ots_1.savefig(output_dir / \"ots-clusters.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1 = plot_points(\n",
    "#     (points_trained_1, points_ots_1),\n",
    "#     (_labels_trained_1, _labels_ots_1),\n",
    "#     None,\n",
    "# #     (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     label_map_1,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1.axes[0].set_xlim(-2.5, 17.5)\n",
    "# fig_1.axes[1].set_xlim(-2.5, 17.5)\n",
    "# fig_1.axes[0].set_ylim(-2.5, 17.5)\n",
    "# fig_1.axes[1].set_ylim(-2.5, 17.5)\n",
    "# fig_1.axes[0].set_xticks([0, 5, 10, 15])\n",
    "# fig_1.axes[0].set_yticks([0, 5, 10, 15])\n",
    "# fig_1.axes[1].set_xticks([0, 5, 10, 15])\n",
    "# fig_1.axes[1].set_yticks([0, 5, 10, 15])\n",
    "# fig_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1.axes[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# fig_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1.savefig(\"clusters.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1 = plot_points(\n",
    "#     (points_trained_1, points_ots_1),\n",
    "#     (_labels_trained_1, _labels_ots_1),\n",
    "#     None,\n",
    "# #     (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     label_map_1,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1 = plot_points(\n",
    "#     (points_trained_1, points_ots_1),\n",
    "#     (dataset_trained_1[\"label\"], dataset_ots_1[\"label\"]),\n",
    "#     (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\"),\n",
    "#     None,\n",
    "#     False,\n",
    "#     **PLOT_KWARGS\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1.axes[0].set_xlim(-2.5, 17.5)\n",
    "# fig_1.axes[1].set_xlim(-2.5, 17.5)\n",
    "# fig_1.axes[0].set_ylim(-2.5, 17.5)\n",
    "# fig_1.axes[1].set_ylim(-2.5, 17.5)\n",
    "# fig_1.axes[0].set_xticks([0, 5, 10, 15])\n",
    "# fig_1.axes[0].set_yticks([0, 5, 10, 15])\n",
    "# fig_1.axes[1].set_xticks([0, 5, 10, 15])\n",
    "# fig_1.axes[1].set_yticks([0, 5, 10, 15])\n",
    "\n",
    "# fig_1.axes[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# fig_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_1.savefig(\"umap.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final plot for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    \"nuke\": \"NFC-Related\",\n",
    "    \"not-nuke\": \"Other\",\n",
    "}\n",
    "PLOT_KWARGS = {\n",
    "    \"linestyle\": \"None\",\n",
    "    \"marker\": \".\",\n",
    "    \"alpha\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels_trained_1 = [label if label >= 0 else int(1e5) for label in labels_trained_1]\n",
    "_labels_ots_1 = [label if label >= 0 else int(1e5) for label in labels_ots_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_set_1 = set(_labels_trained_1 + _labels_ots_1)\n",
    "label_map_1 = {i: f\"Cluster {i + 1: 2d}\" for i in range(max(labels_set_1) + 1)}\n",
    "\n",
    "label_map_1[int(1e5)] = \"Outlier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = (points_trained_1, points_ots_1)[::-1]\n",
    "labels = ((dataset_trained_1[\"label\"], dataset_ots_1[\"label\"])[::-1], (_labels_trained_1, _labels_ots_1)[::-1])\n",
    "label_maps = (LABEL_MAP, label_map_1)\n",
    "titles = (r\"\\textsc{RoBERTa} Large + OSTI Pre-Training\", r\"\\textsc{RoBERTa} Large\")[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "rc(\"text\", usetex=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        _points = points[j]\n",
    "        ax = axes[i, j]\n",
    "        _labels = labels[i][j]\n",
    "        unique_labels = sorted(list(set(_labels)))\n",
    "        idx = {}\n",
    "        for class_name in unique_labels:\n",
    "            idx[class_name] = [i for i, label in enumerate(_labels) if label == class_name]\n",
    "        for class_name in unique_labels:\n",
    "            ax.plot(\n",
    "                _points[idx[class_name], 0],\n",
    "                _points[idx[class_name], 1],\n",
    "                label=label_maps[i][class_name],\n",
    "                **PLOT_KWARGS,\n",
    "            )\n",
    "        if i == 0:\n",
    "            ax.set_title(titles[j])\n",
    "        ax.legend(loc=\"upper right\")  # loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        if j == 0:\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"NFC Labels\")\n",
    "            if i == 1:\n",
    "                ax.set_ylabel(\"BERTopic Cluster Labels\")\n",
    "        ax.set_xlim(-2.5, 25)\n",
    "        ax.set_ylim(-2.5, 18)\n",
    "        ax.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "        ax.set_yticks([0, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(output_dir / \"combined-plots.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
